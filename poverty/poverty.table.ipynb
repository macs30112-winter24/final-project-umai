{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for dynamic scraping\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome('chromedriver')\n",
    "cService = webdriver.ChromeService(executable_path='/Users/lixuewei/Desktop/MACS30112/4/chromedriver-mac-arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service=cService)\n",
    "driver.get(\"https://www.arcgis.com/apps/dashboards/7846c3c37dff4728923609a9f55f849c\")\n",
    "wait = WebDriverWait(driver, 5) # explicit wait for a time period   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom out\n",
    "zoom_out_buttom = driver.find_element(By.XPATH, '/html/body/div/calcite-shell/div[2]/div[2]/div/div/div/margin-container/full-container/div[5]/margin-container/full-container/dashboard-tab-zone/section/div/div/div/div[3]/div/div[4]/div/div[2]')\n",
    "for _ in range(9):\n",
    "    zoom_out_buttom.click()\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_collect_data(driver, num_pages):\n",
    "    \"\"\"\n",
    "    Scrapes data from a table over multiple pages and returns a list of lists.\n",
    "\n",
    "    Args:\n",
    "        driver: A Selenium webdriver instance.\n",
    "        num_pages: The number of pages to scrape.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists, where each inner list represents the poverty data from one page.\n",
    "    \"\"\"    \n",
    "    data_all_pages = []\n",
    "\n",
    "    for _ in range(num_pages):\n",
    "        # Get HTML source code\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Wait for the table data to be present\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        poverty_tds = wait.until(EC.presence_of_all_elements_located((By.TAG_NAME, 'td'))) \n",
    "\n",
    "        # Extract poverty data \n",
    "        poverty_tds = soup.findAll(\"td\")\n",
    "        poverty_values = [td.text for td in poverty_tds]\n",
    "\n",
    "        # Store data for the current page\n",
    "        data_all_pages.append(poverty_values)\n",
    "\n",
    "        # Click the next page button (if it exists)\n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.XPATH, '/html/body/div/calcite-shell/div[2]/div[2]/div/div/div/margin-container/full-container/div[6]/margin-container/full-container/dashboard-tab-zone/section/div/div[3]/calcite-action')\n",
    "            next_page_button.click()\n",
    "\n",
    "        except Exception:  # Handle potential errors if the button isn't found\n",
    "            print(f\"Page navigation may have finished. Collected data from {len(data_all_pages)} pages.\")\n",
    "            break\n",
    "\n",
    "    return data_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_county_poverty = scrape_and_collect_data(driver, num_pages=348)\n",
    "driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Communities in Los Angeles City\n",
    "LA_city_poverty = []\n",
    "for row in LA_county_poverty:\n",
    "    if row[4] == 'Los Angeles City':\n",
    "        LA_city_poverty.append({\n",
    "            \"community\": row[0],\n",
    "            \"2020poverty_rate\": row[3],\n",
    "            \"city\": row[4]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "df = pd.DataFrame(LA_city_poverty)\n",
    "df.to_csv('LA_PovertyRate.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the poverty rate of communities in the three cities\n",
    "def convert_percent_to_float(value):\n",
    "    return float(value.strip('%'))\n",
    "\n",
    "# New York\n",
    "nyc = pd.read_csv('nyc.csv')\n",
    "nyc['poverty.rate'] = nyc['poverty.rate'].apply(convert_percent_to_float)\n",
    "nyc_poverty = nyc[nyc['poverty.rate'] >= 20]\n",
    "nyc_poverty = nyc_poverty.iloc[:, [0, 1, 4]]\n",
    "nyc_poverty.columns = ['borough', 'community', 'poverty.rate']\n",
    "nyc_poverty['city'] = 'New York City'\n",
    "nyc_poverty.to_csv('nyc_poverty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chicago\n",
    "chi = pd.read_csv('chi.csv')\n",
    "chi['Poverty rate'] = chi['Poverty rate'].apply(convert_percent_to_float)\n",
    "chi_poverty = chi[chi['Poverty rate'] >= 20]\n",
    "chi_poverty.columns = ['community', 'poverty.rate']\n",
    "chi_poverty['city'] = 'Chicago'\n",
    "chi_poverty.to_csv('chi_poverty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LA\n",
    "la = pd.read_csv('la.csv')\n",
    "la_poverty = la[la['2020poverty_rate'] >= 20]\n",
    "la_poverty['community'] = la['community'].str[14:]\n",
    "la_poverty.rename(columns={'2020poverty_rate': 'poverty.rate'}, inplace=True)\n",
    "la_poverty.to_csv('la_poverty.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualified communities in three cities\n",
    "all_poverty = pd.concat([nyc_poverty, chi_poverty, la_poverty], axis=0)\n",
    "all_poverty.to_csv('all_poverty.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACS30120TEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
